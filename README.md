# ece457b

Don't read me

Run `naive_bayes.py` to get baseline. It should output something like this:
```
Accuracy = 82.4742857143 %
Classification Report 
              precision    recall  f1-score   support

          0       0.91      0.90      0.91      1677
          1       0.88      0.94      0.91      1935
          2       0.88      0.83      0.86      1767
          3       0.79      0.82      0.80      1766
          4       0.82      0.74      0.78      1691
          5       0.86      0.65      0.74      1653
          6       0.88      0.91      0.89      1754
          7       0.95      0.83      0.88      1846
          8       0.65      0.78      0.71      1702
          9       0.69      0.82      0.75      1709

avg / total       0.83      0.82      0.83     17500
```



Run `run_mnist.py` to run autoencoder. It should output something like this:

```
Training epoch 0, cost  nan
Training epoch 1, cost  nan
Training epoch 2, cost  nan
Training epoch 3, cost  nan
Training epoch 4, cost  nan
Training epoch 5, cost  nan
Training epoch 6, cost  nan
Training epoch 7, cost  nan
Training epoch 8, cost  nan
Training epoch 9, cost  nan
Training epoch 10, cost  nan
Training epoch 11, cost  nan
Training epoch 12, cost  nan
Training epoch 13, cost  nan
The 0% corruption code  ran for 6.05m
Training epoch 14, cost  nan
Accuracy = 83.3085714286 %
Classification Report 
              precision    recall  f1-score   support

          0       0.90      0.89      0.90      1677
          1       0.84      0.97      0.90      1935
          2       0.87      0.81      0.84      1767
          3       0.77      0.79      0.78      1766
          4       0.82      0.84      0.83      1691
          5       0.79      0.74      0.76      1653
          6       0.88      0.87      0.88      1754
          7       0.91      0.85      0.88      1846
          8       0.79      0.77      0.78      1702
          9       0.75      0.79      0.77      1709

avg / total       0.83      0.83      0.83     17500
```
